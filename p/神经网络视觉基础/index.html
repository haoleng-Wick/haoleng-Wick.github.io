<!DOCTYPE html>
<html lang="zh-cn" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='本人整理的关于神经网络视觉的内容，包括了各种图层的介绍，还有一些经典神经网络的结构和原理。'>
<title>神经网络视觉基础</title>

<link rel='canonical' href='https://haoleng-wick.github.io/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/'>

<link rel="stylesheet" href="/scss/style.min.3a32c3f1ade81cbe3a3ab60c3481d3273386dfdf58faacf12aabf0c78b6f2c37.css"><meta property='og:title' content='神经网络视觉基础'>
<meta property='og:description' content='本人整理的关于神经网络视觉的内容，包括了各种图层的介绍，还有一些经典神经网络的结构和原理。'>
<meta property='og:url' content='https://haoleng-wick.github.io/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/'>
<meta property='og:site_name' content='好冷の小窝'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='机器视觉' /><meta property='article:published_time' content='2023-05-11T05:59:13&#43;08:00'/><meta property='article:modified_time' content='2024-02-21T12:35:31&#43;08:00'/><meta property='og:image' content='https://haoleng-wick.github.io/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/cnn_total.jpg' />
<meta name="twitter:title" content="神经网络视觉基础">
<meta name="twitter:description" content="本人整理的关于神经网络视觉的内容，包括了各种图层的介绍，还有一些经典神经网络的结构和原理。"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='https://haoleng-wick.github.io/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/cnn_total.jpg' />
    <link rel="shortcut icon" href="/favicon.ico" />

  



<script async src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>


    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="切换菜单">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/V_hu9f0bc702f392808b5056dd53948f34a5_1454089_300x0_resize_box_1.gif" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">💊</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">好冷の小窝</a></h1>
            <h2 class="site-description">不积跬步，无以至千里</h2>
        </div>
    </header><ol class="social-menu">
            
                <li>
                    <a 
                        href='https://github.com/haoleng-Wick'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://space.bilibili.com/103979628'
                        target="_blank"
                        title="Bilibili"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-bilibili" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M3 10a4 4 0 0 1 4 -4h10a4 4 0 0 1 4 4v6a4 4 0 0 1 -4 4h-10a4 4 0 0 1 -4 -4v-6z" />
  <path d="M8 3l2 3" />
  <path d="M16 3l-2 3" />
  <path d="M9 13v-2" />
  <path d="M15 11v2" />
</svg>

                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://steamcommunity.com/profiles/76561198364816762'
                        target="_blank"
                        title="Steam"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-steam" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M16.5 5a4.5 4.5 0 1 1 -.653 8.953l-4.347 3.009l0 .038a3 3 0 0 1 -2.824 3l-.176 0a3 3 0 0 1 -2.94 -2.402l-2.56 -1.098v-3.5l3.51 1.755a2.989 2.989 0 0 1 2.834 -.635l2.727 -3.818a4.5 4.5 0 0 1 4.429 -5.302z" />
  <circle cx="16.5" cy="9.5" r="1" fill="currentColor" />
</svg>

                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='mailto:yhx2604918320@163.com'
                        target="_blank"
                        title="Mail"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-mail-check" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M11 19h-6a2 2 0 0 1 -2 -2v-10a2 2 0 0 1 2 -2h14a2 2 0 0 1 2 2v6" />
  <path d="M3 7l9 6l9 -6" />
  <path d="M15 19l2 2l4 -4" />
</svg>

                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://haoleng-wick.github.io/index.xml'
                        target="_blank"
                        title="RSS"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="5" cy="19" r="1" />
  <path d="M4 4a16 16 0 0 1 16 16" />
  <path d="M4 11a9 9 0 0 1 9 9" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>主页</span>
            </a>
        </li>
        
        
        <li >
            <a href='/%E5%85%B3%E4%BA%8E/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>关于</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>归档</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>搜索</span>
            </a>
        </li>
        
        
        <li >
            <a href='/%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>友情链接</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
                <li id="i18n-switch">  
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                    <select name="language" onchange="window.location.href = this.selectedOptions[0].value">
                        
                            <option value="https://haoleng-wick.github.io/" selected>中文</option>
                        
                            <option value="https://haoleng-wick.github.io/en/" >English</option>
                        
                    </select>
                </li>
            
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>暗色模式</span>
                </li>
            
        </div>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">目录</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#基础知识">基础知识</a>
      <ol>
        <li><a href="#神经网络的基本原理">神经网络的基本原理</a>
          <ol>
            <li><a href="#卷积层局部感知权值共享--图像特征提取">卷积层（局部感知、权值共享）&ndash;（图像特征提取）</a></li>
            <li><a href="#激活层-通过函数把特征保留并映射到输出端">激活层 (通过函数把特征保留并映射到输出端)</a></li>
            <li><a href="#池化层对特征图进行稀疏处理">池化层（对特征图进行稀疏处理）</a></li>
            <li><a href="#全连接层特征空间--样本标记空间">全连接层（特征空间&ndash;&gt;样本标记空间)</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#图像处理中的卷积神经网络">图像处理中的卷积神经网络</a>
      <ol>
        <li><a href="#lenet模型1998">LeNet模型（1998）</a></li>
        <li><a href="#alexnet模型2012">ALexNet模型（2012）</a></li>
        <li><a href="#googlenet模型2014">GoogleNet模型（2014）</a></li>
        <li><a href="#vggnet模型2014">VGGNet模型（2014）</a></li>
        <li><a href="#ssd模型2016">SSD模型（2016）</a></li>
        <li><a href="#mobilenet2017">MobileNet（2017）</a>
          <ol>
            <li><a href="#mobilenetv1">MobileNetV1</a></li>
            <li><a href="#mobilenet-v2">MobileNet v2</a></li>
          </ol>
        </li>
      </ol>
    </li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/">
                <img src="/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/cnn_total_hue114c50f1abc267ea1a1a271f180c42e_46393_800x0_resize_q75_box.jpg"
                        srcset="/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/cnn_total_hue114c50f1abc267ea1a1a271f180c42e_46393_800x0_resize_q75_box.jpg 800w, /p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/cnn_total_hue114c50f1abc267ea1a1a271f180c42e_46393_1600x0_resize_q75_box.jpg 1600w"
                        width="800" 
                        height="413" 
                        loading="lazy"
                        alt="Featured image of post 神经网络视觉基础" />
                
            </a>
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/%E5%AD%A6%E4%B9%A0/" style="background-color: #2a9d8f; color: #fff;">
                学习
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/">神经网络视觉基础</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            本人整理的关于神经网络视觉的内容，包括了各种图层的介绍，还有一些经典神经网络的结构和原理。
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2023-05-11</time>
            </div>
        <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-edit" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="#9e9e9e" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M7 7h-1a2 2 0 0 0 -2 2v9a2 2 0 0 0 2 2h9a2 2 0 0 0 2 -2v-1" />
  <path d="M20.385 6.585a2.1 2.1 0 0 0 -2.97 -2.97l-8.415 8.385v3h3l8.385 -8.415z" />
  <path d="M16 5l3 3" />
</svg>

                <time class="article-lastmod">2024-02-21</time>
            </div>
        


        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    阅读时长: 16 分钟
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
     
<section class="toc toc--inline">
    <h2 class="">目录</h2>
    <div class="" >
        <nav id="TableOfContents">
  <ol>
    <li><a href="#基础知识">基础知识</a>
      <ol>
        <li><a href="#神经网络的基本原理">神经网络的基本原理</a>
          <ol>
            <li><a href="#卷积层局部感知权值共享--图像特征提取">卷积层（局部感知、权值共享）&ndash;（图像特征提取）</a></li>
            <li><a href="#激活层-通过函数把特征保留并映射到输出端">激活层 (通过函数把特征保留并映射到输出端)</a></li>
            <li><a href="#池化层对特征图进行稀疏处理">池化层（对特征图进行稀疏处理）</a></li>
            <li><a href="#全连接层特征空间--样本标记空间">全连接层（特征空间&ndash;&gt;样本标记空间)</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#图像处理中的卷积神经网络">图像处理中的卷积神经网络</a>
      <ol>
        <li><a href="#lenet模型1998">LeNet模型（1998）</a></li>
        <li><a href="#alexnet模型2012">ALexNet模型（2012）</a></li>
        <li><a href="#googlenet模型2014">GoogleNet模型（2014）</a></li>
        <li><a href="#vggnet模型2014">VGGNet模型（2014）</a></li>
        <li><a href="#ssd模型2016">SSD模型（2016）</a></li>
        <li><a href="#mobilenet2017">MobileNet（2017）</a>
          <ol>
            <li><a href="#mobilenetv1">MobileNetV1</a></li>
            <li><a href="#mobilenet-v2">MobileNet v2</a></li>
          </ol>
        </li>
      </ol>
    </li>
  </ol>
</nav>

    </div>
</section>



    
    
    <h1 id="神经网络视觉基础">神经网络视觉基础</h1>
<h2 id="基础知识">基础知识</h2>
<h3 id="神经网络的基本原理">神经网络的基本原理</h3>
<div align=center><img src="./cnn.png" alt="CNN" /></div>
<blockquote>
<p>神经网络的训练，主要目的就是通过学习算法得到各层神经元之间的连接权重和偏置参数等，然后通过参数计算出输入值的输出。</p>
</blockquote>
<p>卷积神经网络包括<strong>输入层、中间层、输出层</strong>。而中间层可以细化为<strong>卷积层、激活层、池化层和全连接层</strong>。</p>
<h4 id="卷积层局部感知权值共享--图像特征提取">卷积层（局部感知、权值共享）&ndash;（图像特征提取）</h4>
<blockquote>
<p>卷积层中，卷积操作由一个或者多个卷积核(filter)在前层图像上选择相应的区域做卷积运算，然后按一定的步长作滑动运算，依次提取图像区域的像素级特征，图像特征综合后经过<strong>激活函数</strong>激活，完成一次输入到输出的特征提取过程，<strong>卷积后的特征图反映了前层图像的融合特征</strong>。</p>
</blockquote>
<h5 id="卷积操作">卷积操作</h5>
<div align=center><img src="./conver.png" alt="卷积运算" /></div>
<p><strong>经卷积后的矩阵尺寸大小计算公式为</strong>(输入图片大小WxW，卷积核FxF，步长S，padding = P)
$$
N = (W - F + 2P) / S + 1
$$</p>
<h4 id="激活层-通过函数把特征保留并映射到输出端">激活层 (通过函数把特征保留并映射到输出端)</h4>
<blockquote>
<p>卷积神经网络在卷积操作后作用非线性激活函数，可以实现对输入信息的非线性变化，从而使网络的输入和输出产生非线性映射关系，激活层对卷积后的逐元素作用激活函数，实现输入和输出信息的同维。引入激活函数的目的是为了<strong>增加神经网络的非线性拟合能力</strong>。</p>
</blockquote>
<ul>
<li>
<p>&ldquo;为什么一定要非线性？&rdquo;</p>
<p>因为神经网络的每一次输入和输出都是线性求和过程，下一层输出承接了上一层输入函数的线性变换，如果没有非线性激活函数，那么无论神经网络有多少层，最后的输出都是输入的线性组合。这样的线性组合并不能解决复杂的问题。</p>
</li>
</ul>
<h5 id="激活函数">激活函数</h5>
<ol>
<li><em>Sigmoid</em>（又称“逻辑函数”）</li>
</ol>
<p>$$
f(x) = \frac {1} {1 + e^{-x}}
$$</p>
<p>$$
y = \begin{cases} 1, 当S(x) \ge 0.5 \\\
0, 当S(x) &lt; 0.5
\end{cases}
$$</p>
<p>$$
S(x)&rsquo; = \frac{e^{-x}}{(1+e^{-x})^2}
$$</p>
<div align=center><img src="./sigmoid.png" alt="Sigmoid函数图像" /></div>
<p>​	<strong>优点</strong>：</p>
<ul>
<li>值域为[0,1]，他对每个神经元的输出进行了归一化，适合用于将<strong>预测概率</strong>作为输出的模型</li>
<li>梯度平滑，避免了<em>跳跃式</em> 的输出</li>
</ul>
<p>​	<strong>缺点</strong>：</p>
<ul>
<li>接近0或1的神经元梯度趋近于0，容易引起<strong>梯度消失</strong>，即无法反向传播更新权重。</li>
<li><strong>计算量大</strong>，需要更高的算力</li>
</ul>
<ol start="2">
<li><em>ReLU</em>（目前主流的激活函数）</li>
</ol>
<p>$$
f(x) = Max(0, x)
$$</p>
<p>$$
f&rsquo;(x) = Sgn(x)
$$</p>
<p>​		相比sigmoid函数，其<strong>计算速度快</strong>，<strong>收敛速度快</strong>（因为输入为负值时，神经元不会被激活，所以网络很稀疏，能更好的提取相关特征，拟合训练数据）。<em>ReLU</em>函数能够最大化发挥神经元的筛选能力。</p>
<ul>
<li>
<p><strong>不足</strong>：很容易训练过程中使部分kernel废掉，且无法再次被激活。</p>
</li>
<li>
<p>&ldquo;ReLU是分段线性函数，它是怎么实现非线性的？&rdquo;</p>
<p><em>ReLU</em>在整个定义域内并不是线性的，组合多个（线性操作+<em>ReLU</em>）就可以任意划分空间，对于层数比较少的神经网络，用<em>ReLU</em>作为激活函数，那非线性肯定没有那么强，但是当层数多达几十甚至上千，虽然，单独的隐藏层是线性的，但是很多的隐藏层表现出来的就是非线性的。（即用很多小的直线可以拟合出曲线效果一样）。</p>
</li>
</ul>
<ol start="3">
<li><em>Leaky ReLU</em></li>
</ol>
<div align=center><img src="./ReLu.png"  ! alt="ReLu" /></div>
$$
   f(x) = max(\alpha x, x)
$$
   ​	其中$\alpha$为(0,1)的系数，可以有效解决*ReLU*函数神经元死亡的现象。
<ol start="4">
<li><em>Softmax</em> (所有输出概率和为<strong>1</strong>)</li>
</ol>
<p>$$
o_i = \frac {e^{y_i}} {\sum_je^{y_j}}
$$</p>
<ul>
<li>用于多分类问题的激活函数</li>
<li>在零点不可微，负输入的梯度为零会产生“死亡神经元”</li>
</ul>
<blockquote>
<p>对于二分类问题，理论上使用sigmoid和softmax没有区别，因为数学表达式的形式是一样的。
对于多分类非互斥问题（多标签分类）如人和女人，使用sigmoid更合适。
对于多分类互斥问题（单标签分类），使用softmax更合适。</p>
</blockquote>
<h4 id="池化层对特征图进行稀疏处理">池化层（对特征图进行稀疏处理）</h4>
<blockquote>
<p>降低信息冗余，提升模型的尺度不变性、旋转不变性、防止过拟合。</p>
</blockquote>
<p><em>MaxPooling</em>（最大值池化）</p>
<div align=center><img src="./max_pooling.png" alt="最大值池化" /></div>
<h4 id="全连接层特征空间--样本标记空间">全连接层（特征空间&ndash;&gt;样本标记空间)</h4>
<blockquote>
<p>卷积层提取了各种特征，但很多物体可能拥有同一类特征，全连接层相当于<strong>组合了这些特征</strong>起到了<strong>分类器</strong>的功能。</p>
</blockquote>
<div align=center><img src="./full_connection.png" alt="全连接层" /></div>
<h5 id="损失函数">损失函数</h5>
<blockquote>
<p>损失函数是用来衡量模型预测值$f(x)$与真实值$Y$的差异程度的运算函数，他是一个非负实数值函数，通常表示为$L(Y|f(x))$。</p>
</blockquote>
<p><strong>损失函数</strong>使用主要是在模型的训练阶段，每批训练数据送入模型后，通过<strong>前向传播输出预测值</strong>，然后损失函数会计算出预测值和真实值之间的差异值，也就是损失值。得到损失值之后，模型通过<strong>反向传播去更新各个参数</strong>，来降低真实值与预测值之间的损失，使模型越来越准确。</p>
<p>&ldquo;反向传播过程&rdquo;
$$
\omega_{11} = \omega_{11} - \eta \frac{\partial \delta}{\partial \omega_{11}}
$$
通过<strong>链式求导法则</strong>和<strong>梯度下降</strong>，逐步修改权重参数$\omega$。其中 $\eta$ 为学习率，$\delta$为损失值。</p>
<p><strong>基于距离度量的损失函数</strong>：</p>
<ol>
<li>
<p>均方误差损失函数（MSE）
$$
L(Y|f(x)) = \frac{1}{n} \sum_{i=1}^N(Y_i - f(x_i))^2
$$</p>
</li>
<li>
<p>L2损失函数(欧氏距离)
$$
L(Y|f(x)) = \sqrt{\frac{1}{n} \sum_{i=1}^N (Y_i - f(x_i))^2}
$$</p>
</li>
<li>
<p>L2损失函数(曼哈顿距离)
$$
L(Y|f(x)) = \sum_{i=1}^N |Y_i - f(x_i)|
$$</p>
</li>
<li>
<p>Smooth L1损失函数(主要用在目标检测中防止梯度爆炸)
$$
L(Y|f(x)) = \begin{cases}
\frac{1}{2}(Y-f(x))^2 \qquad \quad |Y-f(x)| &lt; 1 \\\
|Y-f(x)|- \frac{1}{2} \qquad |Y-f(x)| \ge 1
\end{cases}
$$</p>
</li>
<li>
<p>huber损失函数(平方损失+绝对损失)
$$
L(Y|f(x)) = \begin{cases}
\frac{1}{2}(Y-f(x))^2 \qquad \qquad |Y-f(x)| \le \delta \\\
\delta |Y-f(x)|- \frac{1}{2} \delta^2 \qquad |Y-f(x)| &gt; \delta
\end{cases}
$$</p>
</li>
</ol>
<p><strong>基于概率分布度量的损失函数</strong>：(涉及概率分布或预测类别出现的概率的问题中应用广泛)</p>
<ol>
<li>
<p>KL散度函数(相对熵)
$$
L(Y|f(x)) = \sum_{i=1}^n Y_i \times log(\frac{Y_i}{f(x_i)})
$$</p>
</li>
<li>
<p><strong>交叉熵损失</strong>
$$
L(Y|f(x)) = - \sum_{i=1}^n Y_i \times logf(x_i)
$$
交叉熵损失函数刻画了实际输出概率与期望输出概率之间的相似度，交叉熵的值越小，两个概率分布就越接近，特别是在正负样本不均衡的分类问题中，常用交叉熵作为损失函数。</p>
<p>目前，交叉熵损失函数是卷积神经网络中最常使用的分类损失函数，它可以有效避免梯度消散。在二分类情况下也叫做对数损失函数。</p>
</li>
<li>
<p>softmax损失函数
$$
L(Y|f(x)) = -\frac{1}{n} \sum_{i=1}^n Y_i \times log \frac{e^{f_{Y_i}}}{\sum_{j=1}^c e^{f_j}}
$$</p>
</li>
<li>
<p>Focal loss
$$
FE = \begin{cases}
-\alpha(1-p)^\gamma log(p) \qquad \quad y = 1 \\\
-(1 - \alpha)p^\gamma log(1-p) \quad y = 0
\end{cases}
$$</p>
</li>
</ol>
<h5 id="优化器">优化器</h5>
<blockquote>
<p>优化器就是在深度学习<strong>反向传播</strong>过程中，<strong>指引损失函数</strong>（目标函数）的各个参数往<strong>正确的方向</strong>更新合适的大小，使得更新后的各个参数让损失函数（目标函数）值不断逼近<strong>全局最小</strong>。</p>
</blockquote>
<ol>
<li><em>SGD优化器</em>（<strong>随机梯度下降法</strong>，易受噪声影响，可能陷入局部最优解）</li>
</ol>
<p>$$
\omega_{t+1} = \omega_t - \alpha \cdot g(\omega_t)
$$</p>
<p>​	$\alpha$为学习率，$g(\omega_t)$ 为$t$ 时刻对参数$\omega_t$ 的损失梯度。</p>
<p>​	<strong>优点</strong>：</p>
<ul>
<li>
<p>每次只用一个样本更新参数，训练速度快</p>
</li>
<li>
<p>随机梯度下降所带来的波动有利于优化的方向从当前的局部极小值点跳到另一个更好的局部极小值点，这样对于非凸函数，最终收敛于一个较好的局部极值点，甚至全局极值点。</p>
</li>
</ul>
<p>​	<strong>缺点</strong>：</p>
<ul>
<li>当遇到局部最优点或鞍点时，梯度为0，无法继续更新参数</li>
<li>沿陡峭方向震荡，而沿平缓维度进展缓慢，难以迅速收敛</li>
</ul>
<ol start="2">
<li><em><strong>SGD+Momentum</strong>优化器</em>（引入动量，抑制样本噪声的干扰）</li>
</ol>
<p>$$
v_t = \eta \cdot v_{t-1} + \alpha \cdot g(\omega_t) \\\
\omega_{t+1} = \omega_t - v_t
$$</p>
<p>​		$\alpha$为学习率，$g(\omega_t)$ 为$t$ 时刻对参数$\omega_t$ 的损失梯度，$\eta(0.9)$ 为动量系数。</p>
<ul>
<li>加入了动量因素，缓解了SGD在局部最优点无法持续更新的问题和震荡幅度过大的问题，但并没有完全解决，当局部沟壑比较深，动量加持用完了，依然会困在局部最优里来回振荡。</li>
</ul>
<ol start="3">
<li><em>Adagrad优化器</em>（自适应学习率，二阶动量）</li>
</ol>
<p>$$
s_t = s_{t-1} + g(\omega_t) \cdot g(\omega_t) \\\
\omega_{t+1} = \omega_t - \frac{\alpha} {\sqrt{s_t + \varepsilon}} \cdot g(\omega_t)
$$</p>
<p>​		$\alpha$为学习率，$g(\omega_t)$ 为$t$ 时刻对参数$\omega_t$ 的损失梯度，$\varepsilon(10^{-7})$ 为防止分母为零的小数。<em>学习率下降过快容易未收敛就停止训练</em></p>
<ol start="4">
<li><em><strong>RMSProp</strong>优化器</em>（自适应学习率）</li>
</ol>
<p>$$
s_t = \eta \cdot s_{t-1} + (1-\eta) \cdot g(\omega_t) \cdot g(\omega_t) \\\
\omega_{t+1} = \omega_t - \frac{\alpha} {\sqrt{s_t + \varepsilon}} \cdot g(\omega_t)
$$</p>
<p>​		$\alpha$为学习率，$g(\omega_t)$ 为$t$ 时刻对参数$\omega_t$ 的损失梯度，$\eta(0.9)$ 控制衰减速度，$\varepsilon(10^{-7})$ 为防止分母为零的小数。</p>
<ol start="5">
<li><em><strong>Adam</strong>优化器</em>（自适应学习率）</li>
</ol>
<p>$$
m_t = \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g(\omega_t) \qquad一阶动量 \\\
v_t = \beta_2 \cdot v_{t-1} + (1 - \beta_2) \cdot g(\omega_t) \cdot g(\omega_t) \quad二阶动量 \\\
\hat{m_t} = \frac{m_t}{1 - \beta^t_1} \quad \hat{\frac{v_t} {1 - \beta^t_2}} \\\
\omega_{t + 1} = \omega_t - \frac{\alpha} {\sqrt{\hat{v_t} + \varepsilon}} \hat{m_t}
$$</p>
<p>​		$\alpha$为学习率，$g(\omega_t)$ 为$t$ 时刻对参数$\omega_t$ 的损失梯度，$\beta_1(0.9)$、$\beta_2(0.999)$ 控制衰减速度，$\varepsilon(10^{-7})$ 为防止分母为零的小数。</p>
<ul>
<li>通过一阶动量和二阶动量，有效控制学习率和梯度方向，防止梯度的振荡和在鞍点的静止。</li>
<li>可能错过全局最优解。自适应学习率算法可能会对前期出现的特征过拟合，后期才出现的特征很难纠正前期的拟合效果。后期Adam的学习率太低，影响了有效的收敛。</li>
</ul>
<h5 id="评估指标--f1分数">评估指标&ndash;F1分数</h5>
<p><strong>二分类：</strong></p>
<div align=center><img src="./Matrix_F1.png" alt="二分类的混淆矩阵" /></div>
<p><strong>阳性样本的真实数量</strong>：$TP + FN$</p>
<p><strong>阴性样本的真实数量</strong>：$FP + TN$</p>
<p>$Precision$ （精确率，又称查准率）（值越高表示误诊数越低）：
$$
Precision = \frac {TP} {TP + FP}
$$
$Recall$ （召回率，又称查全率）（值越高表示漏掉的病人越少）：
$$
Recall = \frac {TP} {TP + FN}
$$
$Accuracy$ （准确率）（正确的样本占样本总数的比例）：
$$
Accuracy = \frac {TP + TN} {TP + FN + FP + TN}
$$
$F1分数$ （综合考虑了精确率和召回率，认为他们同等重要）：
$$
F1 = 2 \times \frac {Precision \times Recall} {Precision + Recall}
$$
<strong>多分类问题：</strong></p>
<ul>
<li>
<p>微观：
$$
(查准率) \quad microP = \frac {TP_1 + TP_2} {TP_1 + FP_1 + TP_2 + FP_2}
$$</p>
<p>$$
(查全率) \quad microR = \frac {TP_1 + TP_2} {TP_1 + FN_1 + TP_2 + FN_2}
$$</p>
<p>$$
microF1 = 2 \times \frac {microP \times microR} {microP + microR}
$$</p>
</li>
<li>
<p>宏观：
$$
(查准率) \quad macroP = \frac {Precision1 + Precision2} {2}
$$</p>
<p>$$
(查全率) \quad macroR = \frac {Recall1 + Recall2} {2}
$$</p>
<p>$$
macroF1 = 2 \times \frac {macroP \times macroR} {macroP + macroR}
$$</p>
</li>
<li>
<p>&ldquo;评估指标的选择&rdquo;</p>
<p>当类别的分布相似时，可以使用准确率，当<strong>类别的分布不平衡时</strong>，F1分数是更好的评估指标。</p>
</li>
</ul>
<h2 id="图像处理中的卷积神经网络">图像处理中的卷积神经网络</h2>
<h3 id="lenet模型1998">LeNet模型（1998）</h3>
<p>由Yann Le Cun于1998年提出，<strong>奠定了卷积神经网络的基础</strong>，由两个卷积层、两个全连接层和一个输出层组成。激活函数采用<em>softmax</em>，池化层采用平均池化。该模型早期主要用于手写字符的识别和分类。</p>
<div align=center><img src="./LeNet.jpg" alt="LeNet" /></div>
<h3 id="alexnet模型2012">ALexNet模型（2012）</h3>
<ul>
<li>首次利用GPU进行网络加速训练</li>
<li>使用了ReLu激活函数，使用最大池化方法</li>
<li>使用了LRN局部相应归一化</li>
<li>在全连接层的前两层使用了Dropout随机失活神经元，减少过拟合</li>
</ul>
<div align=center><img src="./AlexNet.png" alt="AlexNet" /></div>
<blockquote>
<p>过拟合根本原因是<strong>特征维度过多</strong>，模型假设过于复杂，参数过多而训练数据过少，噪声多，导致拟合的函数完美的预测了训练集而对测试集预测结果差。</p>
</blockquote>
<p>卷积计算公式：</p>
<p>$$
N = \frac {(W - F + 2P)} {S} + 1
$$</p>
<p>AlexNet 网络的具体实现</p>
<blockquote>
<p>原图输入224x224 实际上进行了随机裁剪，实际大小为227x227</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">deserialize</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">ALexNet</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">img_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 1</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (227, 227, 3) --&gt; (27, 27, 96)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">                    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv1&#39;</span><span class="p">)(</span><span class="n">img_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (55, 55, 96)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;maxpool1&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 2</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (27, 27, 96) --&gt; (13, 13, 256)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv2&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (27, 27, 256)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;maxpool2&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 3</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (13, 13, 256) --&gt; (13, 13, 384)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv3&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 4</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (13, 13, 384) --&gt; (13, 13, 384)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv4&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 5</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (13, 13, 384) --&gt; (6, 6, 256)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv5&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (13, 13, 256)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;maxpool3&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 6</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (6, 6, 256) --&gt; (1, 4096)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;flatten&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">inputs</span> <span class="o">=</span> <span class="n">img_input</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;alexnet&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">ALexNet</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">227</span><span class="p">,</span> <span class="mi">227</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="googlenet模型2014">GoogleNet模型（2014）</h3>
<ul>
<li>通过引入Inception模块来增加网络<strong>宽度</strong></li>
<li>引入1x1的卷积层来压缩通道数量，降低计算量，从而进一步增加网络<strong>深度</strong></li>
<li>添加两个softmax辅助分类器，缓解梯度消失现象</li>
</ul>
<p>Inception就是把多个卷积或池化操作放在一起组装成一个网络模块。</p>
<h3 id="vggnet模型2014">VGGNet模型（2014）</h3>
<ul>
<li>使用多个3x3小尺寸卷积核和池化层构造深度卷积</li>
<li>在最后使用三层全连接层，用最后一层全连接层的输出作为分类的预测</li>
<li>成功证明了增加网络的深度，可以更好的学习图像中的特征模式</li>
</ul>
<div align=center><img src="./VGG_Net.png" alt="VGG" /></div>
<p>VGG16 网络的具体结构</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span><span class="lnt">90
</span><span class="lnt">91
</span><span class="lnt">92
</span><span class="lnt">93
</span><span class="lnt">94
</span><span class="lnt">95
</span><span class="lnt">96
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span><span class="n">Activation</span><span class="p">,</span><span class="n">Dropout</span><span class="p">,</span><span class="n">Reshape</span><span class="p">,</span><span class="n">Conv2D</span><span class="p">,</span><span class="n">MaxPooling2D</span><span class="p">,</span><span class="n">Dense</span><span class="p">,</span><span class="n">Flatten</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">VGG16</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">img_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 1</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (224, 224, 3) --&gt; (112, 112, 64)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block1_conv1&#39;</span><span class="p">)(</span><span class="n">img_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block1_conv2&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block1_pool&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 2</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (112, 112, 64) --&gt; (56, 56, 128)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block2_conv1&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block2_conv2&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block2_pool&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 3</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (56, 56, 128) --&gt; (28, 28, 256)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block3_conv1&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block3_conv2&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block3_conv3&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block3_pool&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 4</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (28, 28, 256) --&gt; (14, 14, 512)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block4_conv1&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block4_conv2&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block4_conv3&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block4_pool&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Block 5</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (14, 14, 512) --&gt; (7, 7, 512)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block5_conv1&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block5_conv2&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block5_conv3&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;block5_pool&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 对结果进行平铺</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;flatten&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 两次神经元为4096的全连接层</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fc1&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fc2&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 再全连接到1000维，用以分类任务</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">inputs</span> <span class="o">=</span> <span class="n">img_input</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;vgg16&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">intput_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="ssd模型2016">SSD模型（2016）</h3>
<p>SSD是基于一个前向传播反馈的CNN网络，属于one-stage类型。</p>
<ul>
<li>对多尺度特征图进行检测</li>
<li>设置不同长宽比的先验框</li>
</ul>
<div align=center><img src="./SSD_structure.webp" alt="SSD" /></div>
<p>基本的SSD模型是在VGG网络模型的基础上构建的，通过融合不同卷积层的特征图来增强网络对特征的表达能力，采用<strong>多尺度卷积检测</strong>的方法来进行目标检测其结构如图所示：</p>
<p>该模型基于VGG模型(改进版)来提取特征，将各级的卷积特征图作为该一级的特征表示，不同卷积级别的图像卷积特征描述了不同的语义，卷积层越深表达的图像特征信息级别越高。SSD模型中<strong>特征的提取采用的是逐层提取并抽象化的思想，低层的特征主要对应于占比较小的目标，高层的特征主要对应于占比较大的目标的抽象化的信息。</strong> 基本的SSD模型通过<strong>金字塔特征层</strong>进行特征提取，且各特征层之间相互独立，没有目标信息的相互补充，低特征层仅有Conv4_3层用于检测占比小的目标因而在缺乏充足的特征信息的情况下存在特征提取不充分的问题，因而导致<strong>对小型目标的识别效果一般</strong>。</p>
<div align=center><img src="./SSD_Net.jpg" alt="SSD" /></div>
<p>SSD 网络的具体结构：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.engine.topology</span> <span class="kn">import</span> <span class="n">InputSpec</span><span class="p">,</span> <span class="n">Layer</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Activation</span><span class="p">,</span> <span class="n">Concatenate</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Reshape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">vgg</span> <span class="kn">import</span> <span class="n">VGG16</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Normalize</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">3</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">Normalize</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="p">[</span><span class="n">InputSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">],)</span>
</span></span><span class="line"><span class="cl">        <span class="n">init_gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">init_gamma</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">_gamma&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">l2_normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">SSD300</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">21</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># ------ 输入尺寸(300, 300, 3) ------ #</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">net</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># ------- 对主干网络提取到的有效特征进行处理 ------- #</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 对conv4_3的通道进行l2标准化处理 </span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (38, 38, 512)</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv4_3_norm&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_anchors</span> <span class="o">=</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 对预测框的处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># num_anchors表示每个网格点先验框的数量</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 4 是x,y(框中心偏移),h,w(框的高和宽)的调整</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm_mbox_loc&#39;</span><span class="p">]</span>        <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv4_3_norm_mbox_loc&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm_mbox_loc_flat&#39;</span><span class="p">]</span>   <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv4_3_norm_mbox_loc_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm_mbox_loc&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># num_classes是所分的类</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm_mbox_conf&#39;</span><span class="p">]</span>       <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv4_3_norm_mbox_conf&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm_mbox_conf_flat&#39;</span><span class="p">]</span>  <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv4_3_norm_mbox_conf_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm_mbox_conf&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 对fc7层进行处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (19, 19, 1024)</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_anchors</span> <span class="o">=</span> <span class="mi">6</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 预测框的处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 4 是x,y,h,w的调整</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;fc7_mbox_loc&#39;</span><span class="p">]</span>         <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;fc7_mbox_loc&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;fc7&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;fc7_mbox_loc_flat&#39;</span><span class="p">]</span>    <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;fc7_mbox_loc_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;fc7_mbox_loc&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># num_classes是所分的类</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;fc7_mbox_conf&#39;</span><span class="p">]</span>        <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;fc7_mbox_conf&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;fc7&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;fc7_mbox_conf_flat&#39;</span><span class="p">]</span>   <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;fc7_mbox_conf_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;fc7_mbox_conf&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 对conv6_2进行处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (10, 10, 512)</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_anchors</span> <span class="o">=</span> <span class="mi">6</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 预测框的处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 4 是x,y,h,w的调整</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv6_2_mbox_loc&#39;</span><span class="p">]</span>         <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv6_2_mbox_loc&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv6_2&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv6_2_mbox_loc_flat&#39;</span><span class="p">]</span>    <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv6_2_mbox_loc_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv6_2_mbox_loc&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># num_classes是所分的类</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv6_2_mbox_conf&#39;</span><span class="p">]</span>        <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv6_2_mbox_conf&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv6_2&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv6_2_mbox_conf_flat&#39;</span><span class="p">]</span>   <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv6_2_mbox_conf_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv6_2_mbox_conf&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 对conv7_2进行处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (5, 5, 256)</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_anchors</span> <span class="o">=</span> <span class="mi">6</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 预测框的处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 4 是x,y,h,w的调整</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv7_2_mbox_loc&#39;</span><span class="p">]</span>         <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv7_2_mbox_loc&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv7_2&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv7_2_mbox_loc_flat&#39;</span><span class="p">]</span>    <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv7_2_mbox_loc_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv7_2_mbox_loc&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># num_classes是所分的类</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv7_2_mbox_conf&#39;</span><span class="p">]</span>        <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv7_2_mbox_conf&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv7_2&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv7_2_mbox_conf_flat&#39;</span><span class="p">]</span>   <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv7_2_mbox_conf_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv7_2_mbox_conf&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 对conv8_2进行处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (3, 3, 256)</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_anchors</span> <span class="o">=</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 预测框的处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 4是x,y,h,w的调整</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv8_2_mbox_loc&#39;</span><span class="p">]</span>         <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv8_2_mbox_loc&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv8_2&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv8_2_mbox_loc_flat&#39;</span><span class="p">]</span>    <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv8_2_mbox_loc_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv8_2_mbox_loc&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># num_classes是所分的类</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv8_2_mbox_conf&#39;</span><span class="p">]</span>        <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv8_2_mbox_conf&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv8_2&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv8_2_mbox_conf_flat&#39;</span><span class="p">]</span>   <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv8_2_mbox_conf_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv8_2_mbox_conf&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 对conv9_2进行处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (1, 1, 256)</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_anchors</span> <span class="o">=</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 预测框的处理</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 4是x,y,h,w的调整</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv9_2_mbox_loc&#39;</span><span class="p">]</span>         <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv9_2_mbox_loc&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv9_2&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv9_2_mbox_loc_flat&#39;</span><span class="p">]</span>    <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv9_2_mbox_loc_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv9_2_mbox_loc&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># num_classes是所分的类</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv9_2_mbox_conf&#39;</span><span class="p">]</span>        <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv9_2_mbox_conf&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv9_2&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv9_2_mbox_conf_flat&#39;</span><span class="p">]</span>   <span class="o">=</span> <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv9_2_mbox_conf_flat&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv9_2_mbox_conf&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># ------- 将所有结果进行堆叠 ------- #</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;mbox_loc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mbox_loc&#39;</span><span class="p">)([</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm_mbox_loc_flat&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                            <span class="n">net</span><span class="p">[</span><span class="s1">&#39;fc7_mbox_loc_flat&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                            <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv6_2_mbox_loc_flat&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                            <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv7_2_mbox_loc_flat&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                            <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv8_2_mbox_loc_flat&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                            <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv9_2_mbox_loc_flat&#39;</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">                                    
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;mbox_conf&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mbox_conf&#39;</span><span class="p">)([</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv4_3_norm_mbox_conf_flat&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                            <span class="n">net</span><span class="p">[</span><span class="s1">&#39;fc7_mbox_conf_flat&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                            <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv6_2_mbox_conf_flat&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                            <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv7_2_mbox_conf_flat&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                            <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv8_2_mbox_conf_flat&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                            <span class="n">net</span><span class="p">[</span><span class="s1">&#39;conv9_2_mbox_conf_flat&#39;</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (8732, 4)</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;mbox_loc&#39;</span><span class="p">]</span>     <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mbox_loc_final&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;mbox_loc&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (8732, 21)</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;mbox_conf&#39;</span><span class="p">]</span>    <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mbox_conf_logits&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;mbox_conf&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;mbox_conf&#39;</span><span class="p">]</span>    <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mbox_conf_final&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;mbox_conf&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (8732, 25)</span>
</span></span><span class="line"><span class="cl">    <span class="n">net</span><span class="p">[</span><span class="s1">&#39;predictions&#39;</span><span class="p">]</span>  <span class="o">=</span> <span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span> <span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)([</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;mbox_loc&#39;</span><span class="p">],</span> <span class="n">net</span><span class="p">[</span><span class="s1">&#39;mbox_conf&#39;</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">],</span> <span class="n">net</span><span class="p">[</span><span class="s1">&#39;predictions&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>总结而言，SSD是把一张图片划分为不同的网格，当某一物体的中心点落在这个区域，这个物体就由这个网格来确定。</p>
<h3 id="mobilenet2017">MobileNet（2017）</h3>
<h4 id="mobilenetv1">MobileNetV1</h4>
<div align=center><img src="./MobileNetV1.png" alt="网络结构" /></div>
<ol>
<li>Deptwise Convolution(<strong>深度可分离卷积</strong>)(大大减少运算量和参数数量)</li>
</ol>
<p>标准的卷积网络结构：</p>
<div align=center><img src="./mobilenetv1_1.png" alt="CNN" /></div>
<p>深度可分离卷积网络结构：</p>
<div align=center><img src="./mobilenetv1_2.png" alt="深度可分离卷积" /></div>
<p>当输入特征图的 <em>shape</em> 是$D_F \times D_F \times M$，其中 $M$ 为通道数，输出特征图的 <em>shape</em> 为$D_G \times D_G \times N$，通道数为 $N$ ，标准卷积核的尺寸为$D_k \times D_k \times M$时，卷积核的参与个数为 $D_k \cdot D_k \cdot M \cdot N$ 。深度可分离卷积一共分为两个步骤的卷积，其中 <em>Depthwise Convolution</em> 的卷积核为$D_k \times D_k \times 1$， <em>Pointwise Convolution</em> 的卷积核为$1 \times 1 \times M$。那么可以得出如下结论：</p>
<p>标准卷积的运算量：
$$
D_k \cdot D_k \cdot M \cdot N \cdot D_F \cdot D_F = D_F \cdot D_F \cdot M \cdot (D^2_K \cdot N)
$$
深度可分离卷积的运算量：
$$
D_k \cdot D_k \cdot M \cdot D_F \cdot D_F + M \cdot N \cdot D_F \cdot D_F = D_F \cdot D_F \cdot M \cdot (D^2_K + N)
$$
运算量对比：
$$
\frac {D_F \cdot D_F \cdot M \cdot (D^2_K + N)} {D_F \cdot D_F \cdot M \cdot (D^2_k \cdot N)} = \frac {1} {N} + \frac {1} {D^2_K}
$$</p>
<p>深度可分离卷积的tensorflow代码实现：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">DepthwiseConv2D的原函数定义:
</span></span></span><span class="line"><span class="cl"><span class="s2">tf.keras.layers.DepthwiseConv2D(
</span></span></span><span class="line"><span class="cl"><span class="s2">    kernel_size,
</span></span></span><span class="line"><span class="cl"><span class="s2">    strides=(1, 1),
</span></span></span><span class="line"><span class="cl"><span class="s2">    padding=&#34;valid&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s2">    depth_multiplier=1,
</span></span></span><span class="line"><span class="cl"><span class="s2">    data_format=None,
</span></span></span><span class="line"><span class="cl"><span class="s2">    dilation_rate=(1, 1),   # 膨胀率
</span></span></span><span class="line"><span class="cl"><span class="s2">    activation=None,
</span></span></span><span class="line"><span class="cl"><span class="s2">    use_bias=True,  # 是否使用偏置向量
</span></span></span><span class="line"><span class="cl"><span class="s2">    depthwise_initializer=&#34;glorot_uniform&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s2">    bias_initializer=&#34;zeros&#34;,   # 偏置向量的初始值
</span></span></span><span class="line"><span class="cl"><span class="s2">    depthwise_regularizer=None,
</span></span></span><span class="line"><span class="cl"><span class="s2">    bias_regularizer=None,
</span></span></span><span class="line"><span class="cl"><span class="s2">    activity_regularizer=None,
</span></span></span><span class="line"><span class="cl"><span class="s2">    depthwise_constraint=None,
</span></span></span><span class="line"><span class="cl"><span class="s2">    bias_constraint=None,
</span></span></span><span class="line"><span class="cl"><span class="s2">    **kwargs
</span></span></span><span class="line"><span class="cl"><span class="s2">)
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_depthwise_conv_block</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">pointwise_conv_filters</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">alpha</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">depth_multiplier</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">block_id</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;通道的处理channel&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">channel_axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">backend</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&#34;channels_first&#34;</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;alpha超参数&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">pointwise_conv_filters</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">pointwise_conv_filters</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;步长的处理padding&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">strides</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ZeroPadding2D</span><span class="p">(((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_pad_</span><span class="si">%d</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">block_id</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;逐通道卷积&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">DepthwiseConv2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;same&#34;</span> <span class="k">if</span> <span class="n">strides</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&#34;valid&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">depth_multiplier</span><span class="o">=</span><span class="n">depth_multiplier</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_dw_</span><span class="si">%d</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">block_id</span>
</span></span><span class="line"><span class="cl">            <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">channel_axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_dw_</span><span class="si">%d</span><span class="s2">_bn&#34;</span> <span class="o">%</span> <span class="n">block_id</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_dw_</span><span class="si">%d</span><span class="s2">_relu&#34;</span> <span class="o">%</span> <span class="n">block_id</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;逐点卷积&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">pointwise_conv_filters</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;same&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_pw_</span><span class="si">%d</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">block_id</span>
</span></span><span class="line"><span class="cl">            <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Batch Normalization是2015年一篇论文中提出的数据归一化方法，往往用在深度神经网络中激活层之前。
</span></span></span><span class="line"><span class="cl"><span class="s2">    其作用可以加快模型训练时的收敛速度，使得模型训练过程更加稳定，避免梯度爆炸或者梯度消失。并且起到一定的正则化作用，几乎代替了Dropout。&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">channel_axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_pw_</span><span class="si">%d</span><span class="s2">_bn&#34;</span> <span class="o">%</span> <span class="n">block_id</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_pw_</span><span class="si">%d</span><span class="s2">_relu&#34;</span> <span class="o">%</span> <span class="n">block_id</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>&ldquo;Conv2D 和 Depthwise_conv2D的区别&rdquo;</p>
<ul>
<li>
<p>Conv2d在每个通道上卷积，然后求和，Depthwise_conv2D卷积，不求和。</p>
</li>
<li>
<p>Depthwise_conv2D的输出维度和输入维度始终是一致的。</p>
</li>
</ul>
<div class="table-wrapper"><table>
<thead>
<tr>
<th></th>
<th>标准卷积</th>
<th>深度可分离卷积</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>运算特点</strong></td>
<td>每个卷积核的通道与输入通道相同，每个通道单独做卷积运算然后相加</td>
<td>DW卷积：一个卷积核只有一个通道，单独负责一个通道<br>PW卷积：将上一步的特征图在通道方向上进行扩展</td>
</tr>
</tbody>
</table></div>
</li>
</ul>
<ol start="2">
<li><strong>超参数</strong> $\alpha$ $\rho$</li>
</ol>
<ul>
<li>$\alpha$ 宽度系数，对网络中每一层卷积的通道数乘以 $\alpha$ 取值范围[0,1]，比较典型的值为1、0.75、0.5、0.35</li>
</ul>
<p>$$
计算量: \qquad D_k \cdot D_k \cdot \alpha M \cdot D_F \cdot D_F + \alpha M \cdot \alpha N \cdot D_F \cdot D_F
$$</p>
<ul>
<li>$\rho$ 分辨率系数，只改变网络的计算量而不影响网络的参数量</li>
</ul>
<p>$$
计算量: \qquad D_k \cdot D_k \cdot \alpha M \cdot \rho D_F \cdot \rho D_F + \alpha M \cdot \alpha N \cdot \rho D_F \cdot \rho D_F
$$</p>
<blockquote>
<p>DepthWise部分的卷积核容易废掉，即卷积核参数大部分为零。（很重要的一个原因是因为 <em>ReLU</em> 激活函数对0值的梯度是0，后续无论怎么迭代这个节点都不会恢复，即“废掉了”）</p>
</blockquote>
<ul>
<li>
<p>&ldquo;你知道吗？&rdquo;</p>
<p><strong>深度可分离卷积将一个标准卷积分割成了两个卷积（逐深度，逐点），因此减小了参数量，对应也减小了总计算量。</strong> 深度可分离卷积总计算量变小了，但是深度可分离卷积的<strong>层数变多了</strong>。</p>
<p>GPU是并行处理大规模数据(矩阵内积)运算的平台，而CPU则更倾向于对数据串行计算。</p>
<p>因此影响GPU总运算时间的主导因素一般是<strong>网络的层数</strong>。</p>
<p>而影响CPU总运算时间的主导因素是<strong>总计算量</strong>。</p>
<p>所以才会出现MobileNet在某些计算能力有限的CPU平台上速度竟然高于某些GPU平台上的速度。</p>
</li>
</ul>
<p>MobileNet的tensorflow代码实现：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.applications</span> <span class="kn">import</span> <span class="n">imagenet_utils</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.applications.efficientnet</span> <span class="kn">import</span> <span class="n">block</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">MobileNet</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">img_input</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (224, 224, 3)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_conv_block</span><span class="p">(</span><span class="n">img_input</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (112, 112, 32)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (112, 112, 64)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (56, 56, 64)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (56, 56 ,128)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (28, 28, 256)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (28, 28, 256)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (14, 14, 512)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (14, 14, 512)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (7, 7, 1024)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_depthwise_conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">depth_multiplier</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (7, 7, 1024)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">(</span><span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;drpout&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;same&#34;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_preds&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="n">classes</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;reshape_2&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&#34;softmax&#34;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;predictions&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">img_input</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;mobilenet&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_conv_block</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">    <span class="n">filters</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">filters</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">filters</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">kernel</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;same&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv1&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv1_bn&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv1_relu&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_depthwise_conv_block</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">pointwise_conv_filters</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">alpha</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">depth_multiplier</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">block_id</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;通道的处理channel&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">channel_axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">backend</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&#34;channels_first&#34;</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;alpha超参数&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">pointwise_conv_filters</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">pointwise_conv_filters</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;步长的处理padding&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">strides</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ZeroPadding2D</span><span class="p">(((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_pad_</span><span class="si">%d</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">block_id</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;逐通道卷积（处理长宽方向的信息）&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">DepthwiseConv2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;same&#34;</span> <span class="k">if</span> <span class="n">strides</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&#34;valid&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">depth_multiplier</span><span class="o">=</span><span class="n">depth_multiplier</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_dw_</span><span class="si">%d</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">block_id</span>
</span></span><span class="line"><span class="cl">            <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">channel_axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_dw_</span><span class="si">%d</span><span class="s2">_bn&#34;</span> <span class="o">%</span> <span class="n">block_id</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_dw_</span><span class="si">%d</span><span class="s2">_relu&#34;</span> <span class="o">%</span> <span class="n">block_id</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;逐点卷积（处理跨通道方向的信息）&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">pointwise_conv_filters</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;same&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_pw_</span><span class="si">%d</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">block_id</span>
</span></span><span class="line"><span class="cl">            <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">channel_axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_pw_</span><span class="si">%d</span><span class="s2">_bn&#34;</span> <span class="o">%</span> <span class="n">block_id</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv_pw_</span><span class="si">%d</span><span class="s2">_relu&#34;</span> <span class="o">%</span> <span class="n">block_id</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">MobileNet</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="mobilenet-v2">MobileNet v2</h4>
<div align=center><img src="./MobileNetV2.png" alt="网络结构" /></div>
<ol>
<li>
<p>Inverted Residuals(<strong>倒残差结构</strong>)</p>
<p>倒残差结构是从<strong>ResNet</strong>中的残差结构而来的。ResNet中Residuals结构中，先用1x1的卷积实现了降维，然后通过3x3卷积，最后通过1x1卷积实现升维，即<strong>两头大中间小</strong>。</p>
<p>而在<strong>MobileNetV2</strong>中，先用1x1的卷积升维，然后将3x3卷积换为3x3DW卷积，再用1x1的卷积实现降维，即<strong>两头小中间大</strong>。</p>
<p>MobileNetV2的倒残差结构示意图：</p>
</li>
</ol>
<div align=center>
<div class="mermaid">
  
   stateDiagram
   Direction LR
   [*] --> Conv1x1,ReLU6 :升维
   Conv1x1,ReLU6 --> Dwise3x3,ReLU6
   Dwise3x3,ReLU6 --> conv1x1,Linear 
   conv1x1,Linear --> Add :降维，线性激活
   [*] --> Add :残差连接
   Add --> [*]

</div>

</div>
<p><strong>ReLU6</strong>激活函数:
$$
y = ReLU6(x) = min(max(x, 0), 6)
$$</p>
<ol start="2">
<li>
<p>Linear Bottlenecks(线性瓶颈层)</p>
<p>作者发现当信息从高维空间经过非线性映射到低维空间时，会发生信息坍塌，所以在<strong>倒残差结构进行降维操作的时候</strong>，使用了<strong>线性激活函数</strong>（实现方式就是不使用激活函数）。</p>
<p>&ldquo;思考&rdquo;</p>
<p>之所以使用倒残差结构，和线性瓶颈层，是因为作者通过数学证明的方式，得出了<strong>在降维过度时，ReLU会造成大量的信息丢失</strong>，即<strong>升维之后更容易保持可逆</strong></p>
</li>
</ol>
<p>MobileNetV2的tensorflow实现：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.applications</span> <span class="kn">import</span> <span class="n">imagenet_utils</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">MobileNetV2</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">img_input</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">channel_axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">backend</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&#34;channels_first&#34;</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">first_block_filters</span> <span class="o">=</span> <span class="n">_make_divisible</span><span class="p">(</span><span class="mi">32</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 输入(224, 224, 3)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">first_block_filters</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;same&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">name</span><span class="o">=</span><span class="s2">&#34;Conv1&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)(</span><span class="n">img_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">axis</span><span class="o">=</span><span class="n">channel_axis</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;bn_Conv1&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;Conv1_relu&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (112, 112, 32)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (112, 112, 16)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (56, 56, 24)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (28, 28, 32)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (14, 14, 64)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (14, 14, 96)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">160</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">160</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">160</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (7, 7, 160)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">_inverted_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">320</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">block_id</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 宽度因子α</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">alpha</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">last_block_filters</span> <span class="o">=</span> <span class="n">_make_divisible</span><span class="p">(</span><span class="mi">1280</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">last_block_filters</span> <span class="o">=</span> <span class="mi">1280</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (7, 7, 320)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">last_block_filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;Conv_1&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">axis</span><span class="o">=</span><span class="n">channel_axis</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;Conv_1_bn&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;out_relu&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (7, 7, 1280)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">imagenet_utils</span><span class="o">.</span><span class="n">validate_activation</span><span class="p">(</span><span class="s2">&#34;softmax&#34;</span><span class="p">,</span> <span class="s2">&#34;imagenet&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&#34;softmax&#34;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;predictions&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 预测层(1, 1, classes)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 返回模型实例</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">Model</span><span class="p">(</span><span class="n">img_input</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;mobilenetv2&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_inverted_res_block</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">expansion</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">block_id</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;倒残差结构&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">channel_axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">backend</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&#34;channels_first&#34;</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">in_channels</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[</span><span class="n">channel_axis</span><span class="p">]</span> <span class="c1"># 返回张量或变量的shape，作为int或者None条目的元组</span>
</span></span><span class="line"><span class="cl">    <span class="n">pointwise_conv_filters</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">filters</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 确保最后一个1x1卷积上的滤波器个数可以被8整除</span>
</span></span><span class="line"><span class="cl">    <span class="n">pointwise_filters</span> <span class="o">=</span> <span class="n">_make_divisible</span><span class="p">(</span><span class="n">pointwise_conv_filters</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span>
</span></span><span class="line"><span class="cl">    <span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&#34;block_</span><span class="si">{</span><span class="n">block_id</span><span class="si">}</span><span class="s2">_&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">block_id</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 点卷积升维</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">expansion</span> <span class="o">*</span> <span class="n">in_channels</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;same&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">name</span><span class="o">=</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&#34;expand&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">axis</span><span class="o">=</span><span class="n">channel_axis</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">momentum</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">name</span><span class="o">=</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&#34;expand_BN&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&#34;expand_relu&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&#34;expanded_conv_&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Dw卷积</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">stride</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ZeroPadding2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">padding</span><span class="o">=</span><span class="n">imagenet_utils</span><span class="o">.</span><span class="n">correct_pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&#34;pad&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">DepthwiseConv2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">strides</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;same&#34;</span> <span class="k">if</span> <span class="n">stride</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&#34;valid&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">name</span><span class="o">=</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&#34;depthwise&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">axis</span><span class="o">=</span><span class="n">channel_axis</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">momentum</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">name</span><span class="o">=</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&#34;depthwise_BN&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&#34;depthwise_relu&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 点卷积降维，线性激活函数（即None）</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">pointwise_filters</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;same&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">name</span><span class="o">=</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&#34;project&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">axis</span><span class="o">=</span><span class="n">channel_axis</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">momentum</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">name</span><span class="o">=</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&#34;project_BN&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">in_channels</span> <span class="o">==</span> <span class="n">pointwise_filters</span> <span class="ow">and</span> <span class="n">stride</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&#34;add&#34;</span><span class="p">)([</span><span class="n">inputs</span><span class="p">,</span> <span class="n">x</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_make_divisible</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">divisor</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">min_value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">min_value</span> <span class="o">=</span> <span class="n">divisor</span>
</span></span><span class="line"><span class="cl">    <span class="n">new_v</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">min_value</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">v</span> <span class="o">+</span> <span class="n">divisor</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">//</span> <span class="n">divisor</span> <span class="o">*</span> <span class="n">divisor</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 确保向下舍入不会下降超过10%</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">new_v</span> <span class="o">&lt;</span> <span class="mf">0.9</span> <span class="o">*</span> <span class="n">v</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">new_v</span> <span class="o">+=</span> <span class="n">divisor</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">new_v</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">MobileNetV2</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>待续未完。。。</p>
</blockquote>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/">机器视觉</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    <section class="article-lastmod">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



        <span>
            最后更新于 2024-02-21 12:35 CST
        </span>
    </section></footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.staticfile.org/KaTeX/0.16.8/katex.min.css"integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6&#43;HX0sLNAK3q71HotJqlAn"crossorigin="anonymous"
            ><script 
                src="https://cdn.staticfile.org/KaTeX/0.16.8/katex.min.js"integrity="sha384-cpW21h6RZv/phavutF&#43;AuVYrr&#43;dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.staticfile.org/KaTeX/0.16.8/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>
    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">相关文章</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="has-image">
    <a href="/p/tensorflow%E5%85%A5%E9%97%A8/">
        
        
            <div class="article-image">
                <img src="/p/tensorflow%E5%85%A5%E9%97%A8/Tensorflow.8a910a1f19ce6f79e1377de657ac4299_hud8524d9562d7473f3449c190ff1a23cc_42729_250x150_fill_q75_box_smart1.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post Tensorflow入门"
                        
                        data-hash="md5-ipEKHxnOb3nhN33mV6xCmQ==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">Tensorflow入门</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/%E8%A7%86%E8%A7%89%E5%AF%BC%E8%88%AA%E7%BB%BC%E8%BF%B0/">
        
        
            <div class="article-image">
                <img src="/p/%E8%A7%86%E8%A7%89%E5%AF%BC%E8%88%AA%E7%BB%BC%E8%BF%B0/R-C.16e81f38818857b4f78ae52960801bb9_hua8e57d294448123456c3e7a479108155_17488_250x150_fill_q75_box_smart1.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 视觉导航综述"
                        
                        data-hash="md5-FugfOIGIV7T3iuUpYIAbuQ==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">视觉导航综述</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/pytorch%E5%85%A5%E9%97%A8/">
        
        
            <div class="article-image">
                <img src="/p/pytorch%E5%85%A5%E9%97%A8/PyTorch.3467f8688ecab9a3a5a10b6adc491830_hu9f713ad84f2edfa72e78551edd5f644f_73867_250x150_fill_q75_box_smart1.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post Pytorch入门"
                        
                        data-hash="md5-NGf4aI7KuaOloQtq3EkYMA==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">Pytorch入门</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/%E4%BC%A0%E7%BB%9F%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/">
        
        
            <div class="article-image">
                <img src="/p/%E4%BC%A0%E7%BB%9F%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/R-C.d67e3b6f1bb78779f5bd074efaf98994_hu897fca54ae8e34409121667f57e687d2_226190_250x150_fill_box_smart1_3.png" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 传统机器视觉基础"
                        
                        data-hash="md5-1n47bxu3h3n1vQdO&#43;vmJlA==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">传统机器视觉基础</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/c%E8%AF%AD%E8%A8%80%E6%9D%82%E8%AE%B0/">
        
        
            <div class="article-image">
                <img src="/p/c%E8%AF%AD%E8%A8%80%E6%9D%82%E8%AE%B0/CLanguage.f870404c5bc35c1f21eb47034bf943e3_hu49e21fe23b7011216ea2a8bfb0c93686_71510_250x150_fill_q75_box_smart1.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post C语言杂记"
                        
                        data-hash="md5-&#43;HBATFvDXB8h60cDS/lD4w==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">C语言杂记</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    <script
    src="https://giscus.app/client.js"
    data-repo="haoleng-Wick/haoleng-Wick.github.io"
    data-repo-id="R_kgDOLVRoiA"
    data-category="Announcements"
    data-category-id="DIC_kwDOLVRoiM4CeWbt"
    data-mapping="pathname"
    data-strict="0"
    data-reactions-enabled="1"
    data-emit-metadata="0"
    data-input-position="top"
    data-theme="light"
    data-lang="en"
    crossorigin="anonymous"
    async
></script>
<script>
    function setGiscusTheme(theme) {
        let giscus = document.querySelector("iframe.giscus-frame");
        if (giscus) {
            giscus.contentWindow.postMessage(
                {
                    giscus: {
                        setConfig: {
                            theme: theme,
                        },
                    },
                },
                "https://giscus.app"
            );
        }
    }

    (function () {
        addEventListener("message", (e) => {
            if (event.origin !== "https://giscus.app") return;
            handler();
        });
        window.addEventListener("onColorSchemeChange", handler);

        function handler() {
            if (document.documentElement.dataset.scheme === "light") {
                setGiscusTheme('light');
            } else {
                setGiscusTheme('noborder_dark');
            }
        }
    })();
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2023 - 
        
        2024 欢迎前来窜门子
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.3/photoswipe.min.js"integrity="sha512-2R4VJGamBudpzC1NTaSkusXP7QkiUYvEKhpJAxeVCqLDsgW4OqtzorZGpulE3eEA7p&#43;&#43;U0ZYmqBwO3m&#43;R2hRjA=="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.3/photoswipe-ui-default.min.js"integrity="sha512-SxO0cwfxj/QhgX1SgpmUr0U2l5304ezGVhc0AO2YwOQ/C8O67ynyTorMKGjVv1fJnPQgjdxRz6x70MY9r0sKtQ=="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.3/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.3/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdnjs.cloudflare.com/ajax/libs/vibrant.js/1.0.0/Vibrant.min.js"integrity="sha512-V6rhYmJy8NZQF8F0bhJiTM0iI6wX/FKJoWvYrCM15UIeb6p38HjvTZWfO0IxJnMZrHWUJZJqLuWK0zslra2FVw=="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>
<script src="https://npm.elemecdn.com/nprogress@0.2.0/nprogress.js" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://npm.elemecdn.com/nprogress@0.2.0/nprogress.css" crossorigin="anonymous" />
<script>
    NProgress.start();
    document.addEventListener("readystatechange", () => {
        if (document.readyState === "interactive") NProgress.inc(0.8);
        if (document.readyState === "complete") NProgress.done();
    });
</script>

    </body>
</html>
